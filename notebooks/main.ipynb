{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Travel insurance prediction model\n",
    "\n",
    "This is the main notebook of travel insurance prediction model which composes of 3 parts:\n",
    "1. Data preparation\n",
    "2. Model evaluation\n",
    "\n",
    "Note - reasons for this specific data preperation and modelling choices are described in the [Exploratory_analysis.ipynb](./Exploratory_analysis.ipynb) file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set\n",
    "The dataset contains information about customers, including demographics and travel history. The target variable is TravelInsurance which indicates whether a customer purchased travel insurance (1) or not (0).The data can be downloaded from [Kaggle](https://www.kaggle.com/datasets/tejashvi14/travel-insurance-prediction-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "- Build a model to predict which customers will buy travel insurance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biases\n",
    "\n",
    "In the data there are some biases which thus affect model predictions:\n",
    "- Class imbalance: There is 2 times more customers who did not buy insurance than who did.\n",
    "- Data is based on Tour and travel company customers, they might be different from general population and other insurance companies customers.\n",
    "- This data focuses on travel insurance, which might be different from other types of insurance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain knowledge\n",
    "I am not an insurance expert, but I use statistical and machine learning knowledge to build a model to predict travel insurance purchases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from utils.evaluations import evaluate_pipeline, print_single_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/train_travel_insurance.csv\")\n",
    "val_df = pd.read_csv(\"data/val_travel_insurance.csv\")\n",
    "test_df = pd.read_csv(\"data/test_travel_insurance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data\n",
    "In this section we prepare the data for modeling by handling categorical features, missing values, and scaling numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(drop=\"first\", sparse_output=False)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numerical_transformer, [\"Age\", \"AnnualIncome\", \"FamilyMembers\"]),\n",
    "        (\n",
    "            \"cat\",\n",
    "            categorical_transformer,\n",
    "            [\n",
    "                \"Employment Type\",\n",
    "                \"GraduateOrNot\",\n",
    "                \"FrequentFlyer\",\n",
    "                \"EverTravelledAbroad\",\n",
    "                \"ChronicDiseases\",\n",
    "            ],\n",
    "        ),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will process both train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_val_df = pd.concat([train_df, val_df])\n",
    "X_train = train_and_val_df.drop(\"TravelInsurance\", axis=1)\n",
    "y_train = train_and_val_df[\"TravelInsurance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.drop(\"TravelInsurance\", axis=1)\n",
    "y_test = test_df[\"TravelInsurance\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "In this section I will evaluate the model on the test set. Model has not seen this data during training and validation, thus it is a good indicator of the model's generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.822742</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.616822</td>\n",
       "      <td>0.713514</td>\n",
       "      <td>0.787992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model  Accuracy  Precision    Recall  F1 Score       AUC\n",
       "0  XGBoost  0.822742   0.846154  0.616822  0.713514  0.787992"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\n",
    "            \"classifier\",\n",
    "            xgb.XGBClassifier(\n",
    "                learning_rate=0.1, max_depth=5, n_estimators=200, random_state=42\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "results = evaluate_pipeline(full_pipeline, X_train, X_test, y_train, y_test)\n",
    "print_single_result(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model achieves similar performance on test set as when cross validated. This is good sign that model is not overfitting. On test set it has better recall and precision by 1%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"models\").mkdir(exist_ok=True)\n",
    "with Path(\"models/full_pipeline.pkl\").open(\"wb\") as f:\n",
    "    pickle.dump(results[\"pipeline\"], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model which predicts travel insurance purchase likelihood predicts:\n",
    "- Model correctly predicts 82.3% of customers who will buy or will not buy insurance. But data has class imbalance, so it is better to look at precision and recall.\n",
    "- When model predicts that customer will buy insurance it is correct 84.6% of the time.\n",
    "- The model identifies 61.7% of all actual insurance buyers.\n",
    "- AUC of 78.8% indicates the model has good discriminative ability, that is it is able to distinguish between customers who will buy and will not buy insurance and is better than random guessing at 50%\n",
    "\n",
    "This model can be particularly useful for targeted marketing campaigns where the focus is on customers who are more likely to buy insurance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improvements\n",
    "- Use more data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
